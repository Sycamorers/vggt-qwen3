model:
  # Tiny HF model to keep the smoke test CPU-friendly.
  name_or_path: sshleifer/tiny-gpt2
  tokenizer_path: sshleifer/tiny-gpt2
  # Use the lightweight stub in src/models/vggt_qwen3_vlm.py
  vision_backbone: mock
  num_vis_tokens: 8
  geom_tokens: 1
  projector: configs/perceiver_small.yaml
  freeze_vision: true
  freeze_text_layers: []
  dtype: float32

data:
  datasets:
    toy: data/processed/toy/*.json
  mix_ratio:
    toy: 1.0
  num_views: 2
  image_size: 224
  max_length: 512
  view_dropout: 0.0

train:
  precision: "no"
  optimizer: adamw
  lr: 1.0e-4
  proj_lr: 1.0e-3
  weight_decay: 0.01
  warmup_ratio: 0.0
  batch_size_per_gpu: 1
  grad_accum: 1
  max_steps: 5
  save_every_steps: 0
  eval_every_steps: 0
  log_every_steps: 1
  seed: 7

lora:
  enable: false
